{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASzDXYj0CVyq"
      },
      "source": [
        "## CGAS Assignment 1\n",
        "- Parisha Agrawal | 2021270\n",
        "- Annu Kumari | 2021312"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1SG4rZhCVyu"
      },
      "source": [
        "## Q1) Complete the following analysis using the recipes’ data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Scrape (using libraries such as BeautifulSoup) any 10,000 recipes. Submit the raw data. [5]\n",
        "Include recipe titles, ingredient phrases, cooking instructions, and other relevant details."
      ],
      "metadata": {
        "id": "I6CE3Zl1VLMb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nQrJYZZfCVyw"
      },
      "outputs": [],
      "source": [
        "# !pip install requests\n",
        "# !pip install beautifulsoup4\n",
        "# !pip install pandas\n",
        "# !pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_DliB6WCVyx"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import json\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from requests.adapters import HTTPAdapter, Retry"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_url_rx = r\"https://www\\.allrecipes\\.com/recipe/\\d+/.+\"\n",
        "recipes_url_rx = r\"https:\\/\\/www\\.allrecipes\\.com\\/recipes\\/\\d+\\/.+\\/\""
      ],
      "metadata": {
        "id": "7ztjiF4vGNjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prep_time(duration):\n",
        "    # PT10M to 10 mins\n",
        "    minutes = re.search(r'(\\d+)M', duration)\n",
        "    hours = re.search(r'(\\d+)H', duration)\n",
        "    days = re.search(r'(\\d+)D', duration)\n",
        "\n",
        "    formatted_duration = []\n",
        "\n",
        "    if days:\n",
        "        formatted_duration.append(f\"{days.group(1)} days\")\n",
        "    if hours:\n",
        "        formatted_duration.append(f\"{hours.group(1)} hours\")\n",
        "    if minutes:\n",
        "        formatted_duration.append(f\"{minutes.group(1)} mins\")\n",
        "\n",
        "    return \" \".join(formatted_duration) if formatted_duration else \"No prep time found\""
      ],
      "metadata": {
        "id": "Jmfro4KYuiUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_urls(s, max_categories):\n",
        "    recipes_categories = []\n",
        "    try:\n",
        "        categories_req = s.get(\"https://www.allrecipes.com/recipes-a-z-6735880\")\n",
        "    except Exception:\n",
        "        print(\"Error in retrieving categories\")\n",
        "        return recipes_categories\n",
        "\n",
        "    if categories_req.status_code == 200:\n",
        "        soup = BeautifulSoup(categories_req.text, \"html.parser\")\n",
        "        links = soup.find_all(\"a\", class_=\"mntl-link-list__link\")\n",
        "        for link in links:\n",
        "            if max_categories == len(recipes_categories):\n",
        "                break\n",
        "            href = link.get(\"href\")\n",
        "            if href and re.match(recipes_url_rx, href):\n",
        "                recipes_categories.append(href)\n",
        "    else:\n",
        "        print(\"Failed to retrieve categories\")\n",
        "\n",
        "    return recipes_categories"
      ],
      "metadata": {
        "id": "fyUhQ64ntB1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category(s, category_url):\n",
        "    try:\n",
        "        category_req = s.get(category_url)\n",
        "        return category_req\n",
        "    except Exception:\n",
        "        print(f\"Failed to retrieve the category: {category_url}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "rkQLTu26t0p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category_recipes_urls(category):\n",
        "    category_urls = []\n",
        "    recipes_soup = BeautifulSoup(category.text, \"html.parser\")\n",
        "    recipes_soup = recipes_soup.find_all(\"a\", {\"class\": \"card\"})\n",
        "    for recipe_link in recipes_soup:\n",
        "        if re.match(recipe_url_rx, recipe_link[\"href\"]):\n",
        "            category_urls.append(recipe_link[\"href\"])\n",
        "    return category_urls"
      ],
      "metadata": {
        "id": "-EkK5Rx_waFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recipe(s, recipe_url):\n",
        "    try:\n",
        "        recipe_req = s.get(recipe_url)\n",
        "    except Exception:\n",
        "        print(f\"Failed to retrieve the recipe: {recipe_url}\")\n",
        "        return\n",
        "\n",
        "    if recipe_req and recipe_req.status_code == 200:\n",
        "        recipe_soup = BeautifulSoup(recipe_req.text, \"html.parser\")\n",
        "        recipe_data = recipe_soup.find(\"script\", {\"class\": \"allrecipes-schema\"})\n",
        "\n",
        "        if recipe_data:\n",
        "            recipe_json = json.loads(recipe_data.text)[0]\n",
        "            headline = recipe_json.get(\"headline\", \"No headline found\")\n",
        "            recipe_instructions = recipe_json.get(\"recipeInstructions\", [])\n",
        "            recipe_ingredients = recipe_json.get(\"recipeIngredient\", [])\n",
        "\n",
        "            # Optionals\n",
        "            region_cuisine = recipe_json.get(\"recipeCuisine\", \"No cuisine found\")\n",
        "            if isinstance(region_cuisine, list):\n",
        "                region_cuisine = \", \".join(region_cuisine)\n",
        "\n",
        "            servings = recipe_json.get(\"recipeYield\", \"No servings found\")\n",
        "            if isinstance(servings, list):\n",
        "                servings = \", \".join(servings)\n",
        "\n",
        "            recipe_prep_time = recipe_json.get(\"prepTime\", \"No prep time found\")\n",
        "            formatted_prep_time = format_prep_time(recipe_prep_time)\n",
        "\n",
        "            # Save to csv\n",
        "            with open(\"Q1_a_scraped_recipes.csv\", mode=\"a\", newline='', encoding=\"utf-8\") as file:\n",
        "                writer = csv.writer(file)\n",
        "                if file.tell() == 0:\n",
        "                    writer.writerow([\"Recipe name\", \"Recipe URL\", \"List of ingredient phrases\", \"List of instructions\", \"Region/Cuisine\", \"Servings\", \"Preparation time\"])\n",
        "\n",
        "                formatted_instructions = [step['text'] for step in recipe_instructions]\n",
        "                # formatted_ingredients = \" \".join(recipe_ingredients)\n",
        "                writer.writerow([headline, recipe_url, recipe_ingredients, formatted_instructions, region_cuisine, servings, formatted_prep_time])"
      ],
      "metadata": {
        "id": "rj7NK-6QIUDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_recipes(s, progress, recipe_categories, max_categories, max_recipes):\n",
        "    global recipes_count\n",
        "    for i, category_url in enumerate(recipe_categories):\n",
        "        if i == max_categories:\n",
        "            break\n",
        "        progress[\"category\"] = category_url\n",
        "        category = get_category(s, category_url)\n",
        "        if not category:\n",
        "            continue\n",
        "        category_urls = get_category_recipes_urls(category)\n",
        "        progress[\"category_urls\"] = category_urls\n",
        "        for j, recipe_url in enumerate(category_urls):\n",
        "            if recipes_count == max_recipes:\n",
        "                break\n",
        "            recipes_count += 1\n",
        "            progress[\"recipe\"] = recipe_url\n",
        "            get_recipe(s, recipe_url)\n",
        "            progress[\"downloaded_count\"] += 1\n",
        "            progress[\"category_urls\"].pop(j)\n",
        "            if len(progress[\"categories\"]) != 0:\n",
        "                progress[\"categories\"].pop(i)"
      ],
      "metadata": {
        "id": "KmfWflQ1lYZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = requests.Session()\n",
        "retries = Retry(total=6, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504])\n",
        "s.mount('http://', HTTPAdapter(max_retries=retries))\n",
        "s.headers = {\"User-Agent\": \"Mozilla/5.0 (X11 Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome /\"}\n",
        "s.timeout = 12"
      ],
      "metadata": {
        "id": "I03vlgyPuBE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_recipes = 10005\n",
        "max_categories = 2000\n",
        "recipes_count = 0\n",
        "progress = {\n",
        "    \"category\": None,\n",
        "    \"recipe\": None,\n",
        "    \"downloaded_count\": 0,\n",
        "    \"categories\": [],\n",
        "    \"category_urls\": [],\n",
        "    \"recipe_urls\": [],\n",
        "    \"failed_recipes\": []\n",
        "}"
      ],
      "metadata": {
        "id": "KceOeCgwuDm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_categories = parse_urls(s, max_categories)"
      ],
      "metadata": {
        "id": "6bkbBrO7Jn6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_recipes(s, progress, recipe_categories, max_categories, max_recipes)"
      ],
      "metadata": {
        "id": "QlMXcIuMMezA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) Write a script to extract information about the ‘name of the ingredients’ from the ingredients section using Named Entity Recognition."
      ],
      "metadata": {
        "id": "2cdobSHpOlL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "id": "V9KE_AbT7t6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy's english model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "qe_F_9yt7xI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = [{\"POS\": \"NOUN\"}, {\"IS_ALPHA\": True, \"OP\": \"?\"}]\n",
        "matcher.add(\"INGREDIENTS_PATTERN\", [pattern])\n",
        "\n",
        "fluffwords = set([\n",
        "    'a', 'all', 'an', 'and', 'as', 'beaten', 'baked', 'boiled', 'browned', 'chopped', 'clove', 'coarsely',\n",
        "    'cold', 'cooked', 'crushed', 'cubed', 'cup', 'cups', 'dash', 'diced', 'divided', 'finely', 'fresh', 'g',\n",
        "    'garnished', 'gram', 'grams', 'grated', 'ground', 'halved', 'inch', 'kg', 'l', 'large', 'liter', 'liters',\n",
        "    'melted', 'medium', 'medium-sized', 'minced', 'ml', 'of', 'or', 'ounce', 'ounces', 'package', 'pinch',\n",
        "    'pound', 'pounds', 'purpose', 'raw', 'roasted', 'shredded', 'slice', 'sliced', 'small', 'steamed',\n",
        "    'stick', 'sweetened', 'tablespoon', 'tablespoons', 'taste', 'teaspoon', 'teaspoons', 'the', 'thick',\n",
        "    'thickly', 'thinly', 'to', 'unsalted', 'unsweetened', 'with', 'whole'\n",
        "])"
      ],
      "metadata": {
        "id": "2csqGODskkfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rx = re.compile(r'\\b\\d+(\\.\\d+)?\\b')\n",
        "fluffwords_rx = [re.compile(r'\\b' + re.escape(fluff) + r'\\b') for fluff in fluffwords]"
      ],
      "metadata": {
        "id": "K39PJanHksGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_recipes = pd.read_csv('Q1_a_scraped_recipes.csv')"
      ],
      "metadata": {
        "id": "6IW1ZmKf7zWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign random Recipe IDs to all recipes\n",
        "df_recipes['Recipe ID'] = ['Recipe ' + str(i + 1) for i in range(len(df_recipes))]"
      ],
      "metadata": {
        "id": "CleVGf0J79lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_ingredient(ingredient):\n",
        "    ingredient = re.sub(r'\\(.*?\\)', '', ingredient)\n",
        "    for pattern in fluffwords_rx:\n",
        "        ingredient = pattern.sub('', ingredient)\n",
        "    ingredient = num_rx.sub('', ingredient)\n",
        "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
        "    return ingredient\n",
        "\n",
        "def extract_ingredient_entities(ingredient_phrase):\n",
        "    ingredient_phrase = re.sub(r'\\(.*?\\)', '', ingredient_phrase)\n",
        "    for pattern in fluffwords_rx:\n",
        "        ingredient_phrase = pattern.sub('', ingredient_phrase)\n",
        "    ingredient_phrase = num_rx.sub('', ingredient_phrase)\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', ingredient_phrase).strip()\n",
        "\n",
        "    doc = nlp(cleaned_text)\n",
        "    ingredients = [chunk.text for chunk in doc.noun_chunks] or [cleaned_text]\n",
        "    cleaned_ingredients = [clean_ingredient(ingredient) for ingredient in ingredients]\n",
        "    return cleaned_ingredients"
      ],
      "metadata": {
        "id": "hwP1VLBk8leR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process ingredient phrases and extract cleaned ingredients\n",
        "ingredient_data = []\n",
        "for index, row in df_recipes.iterrows():\n",
        "    recipe_id = row['Recipe ID']\n",
        "    ingredient_phrases = eval(row['List of ingredient phrases'])\n",
        "    for phrase in ingredient_phrases:\n",
        "        ingredients = extract_ingredient_entities(phrase)\n",
        "        ingredient_data.extend({'Recipe ID': recipe_id, 'Ingredient': ingredient} for ingredient in ingredients if ingredient)"
      ],
      "metadata": {
        "id": "J-3ueWWY8nwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save extracted ingredients\n",
        "ingredient_df = pd.DataFrame(ingredient_data).drop_duplicates()\n",
        "ingredient_df.to_csv('Q1_b_ingredient_entities.csv', index=False)\n",
        "print(\"Ingredient entities saved to 'Q1_b_ingredient_entities.csv'.\")"
      ],
      "metadata": {
        "id": "L7kiVziaTJi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17271c9-35e7-4a55-d95a-2c17597b8fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredient entities saved to 'Q1_b_ingredient_entities.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) Store recipes in the form of a (Recipe ID)—(Ingredient Name) form."
      ],
      "metadata": {
        "id": "m2Z-87fcTYTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "id": "EoxykwOchSaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Q1_b_ingredient_entities.csv')\n",
        "recipe_ids = df['Recipe ID'].unique()\n",
        "\n",
        "# 100 random recipe IDs\n",
        "selected_recipe_ids = random.sample(list(recipe_ids), 100)\n",
        "\n",
        "filtered_df = df[df['Recipe ID'].isin(selected_recipe_ids)]\n",
        "\n",
        "with open('Q1_c_selected_recipes.txt', 'w') as file:\n",
        "    # file.write(f\"Recipe ID — Ingredient Name\\n\")\n",
        "    for _, row in filtered_df.iterrows():\n",
        "        file.write(f\"{row['Recipe ID']} — {row['Ingredient']}\\n\")\n",
        "\n",
        "print(\"Selected recipes-ingredients saved to 'Q1_c_selected_recipes.txt'\")"
      ],
      "metadata": {
        "id": "qFFwM0pJQh7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198c45a1-377f-4626-d916-7a09af9af1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected recipes-ingredients saved to 'Q1_c_selected_recipes.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ka1CAY9-qwjp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}